# ====================== Prometheus stack ============================
alertmanager:
  enabled: true
  image:
    repository: quay.io/prometheus/alertmanager
    tag: v0.21.0
    pullPolicy: IfNotPresent
  persistentVolume:
    enabled: true
    size: 500Mi
  service:
    port: 80
    targetPort: 9093
    nodePort: 30093
    type: NodePort
alertmanagerFiles:
  alertmanager.yml:
    global:
    route:
      group_by: ['instance' , 'alertname']
      group_wait: 10s
      group_interval: 30s
      repeat_interval: 30m
      receiver: Stelthlab
      routes:
        - match_re:
            environment: .*
          routes:
            - match:
                owner: devops
              receiver: Stelthlab
    receivers:
      - name: Stelthlab
        slack_configs:
          - send_resolved: true
            api_url: https://hooks.slack.com/services/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
            channel: 'alerts'
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Alert From Prometheus Alertmanager'
            text: >-
              {{ range .Alerts }}

              *Alert:* {{ .Labels.instance }} - *`{{ .Labels.severity }}`*

              *AlertName:* {{ .Labels.alertname }}

              *Summary:* {{ .Annotations.summary }}

              *Description:* {{ .Annotations.description }}
              {{ end }}



pushgateway:
  enabled: false

nodeExporter:
  enabled: false

netdata:
  enabled: true
  namespace: netdata
  image: paopsmon/netdata:latest
  hostNetwork: true
  resources:
    requests:
      memory: 300Mi
      cpu: 100m
    limits:
      memory: 500Mi
      cpu: 100m

kubeStateMetrics:
  enabled: true
  namespaceOverride: prometheus
  fullnameOverride: kube-state-metrics

server:
#  prefixURL: "/prometheus"
#  baseURL: "kubernetes.docker.internal"

  ingress:
    enabled: true
    annotations:
      traefik.ingress.kubernetes.io/router.entrypoints: web
  #      traefik.ingress.kubernetes.io/router.middlewares: monitoring-stack-prometheus-prefix@kubernetescrd
    hosts:
    - prometheus.docker.internal

#    path: /prometheus
#    pathType: Prefix

  enabled: true
  persistentVolume:
    enabled: false
  retention: 1h
#  service:
#    annotations:
#      service.beta.kubernetes.io/aws-load-balancer-internal: "true"
#      service.beta.kubernetes.io/aws-load-balancer-type: nlb
#    clusterIP: ""
#    labels: {}
#    servicePort: 9090
#    targetPort: 9090
#    type: LoadBalancer
  service:
    annotations: {}
    # clusterIP: ""
    labels: {}
    port: 9090
    targetPort: 9090
    # nodePort: 32636
    type: ClusterIP

  global:
    scrape_interval: 10s
    scrape_timeout: 10s
    evaluation_interval: 10s
  alertmanagers:
    - scheme: http
      static_configs:
        - targets:
            - "monitoring-stack-alertmanager.prometheus.svc"
serverFiles:
  alerting_rules.yml:
    groups:
      - name: 'Kubernetes Has New Pod'
        rules:
          - alert: 'K8s Has New Pod'
            expr: >
              count by (provider,cluster_name,region,environment,namespace,label_app,pod)
                (sum by (provider,cluster_name,region,environment,namespace,label_app,pod)
                  (avg_over_time(kube_pod_labels{label_app=~".+"}[2m])) * 0 + on (pod,namespace) group_left
                  sum by (pod,namespace)
                  (time() - max_over_time(kube_pod_created[2m])) > 200 < 300) > 0
            for: 10s
            labels:
              owner: devops
              severity: informational
            annotations:
              summary: '{{ $labels.provider }}/{{ $labels.region }}: {{ $labels.cluster_name }}, Env: {{ $labels.environment }}, Pod: {{ $labels.pod }}'
              description: 'Kubernetes created {{ $value }} new "{{ $labels.label_app }}" pods'
              troubleshooting: "No actions need"
      - name: 'Kubernetes Node Status'
        rules:
          - alert: 'K8s Node Status'
            expr: >
              sum by (provider,cluster_name,region,environment,instance)
                          (label_replace
                            (avg_over_time(kube_node_status_condition{condition="Ready",status="false"}[1m]),
                            "instance", "$0", "node", ".*"
                          )
                        ) == 1
            for: 30s
            labels:
              owner: devops
              severity: critical
            annotations:
              value: '{{ $labels.phase }}'
              summary: '{{ $labels.provider }}/{{ $labels.region }}: {{ $labels.cluster_name }}, Env: {{ $labels.environment }}, Condition: NotReady'
              description: "Kubernetes node: {{ $labels.instance }} is not Ready"
              troubleshooting: "Inform Higher Level OPS"
      - name: 'Kubernetes Pod Status'
        rules:
          - alert: 'Pod Status'
            expr: >
              sum by (provider,cluster_name,region,environment,phase,pod,namespace)
                (avg_over_time(kube_pod_status_phase{phase!~"Running|Succeeded"}[1m])) == 1
            for: 1m
            labels:
              severity: critical
              owner: devops
              customer: '{{ $labels.provider }}:{{ $labels.region }}:{{ $labels.cluster_name }}:{{ $labels.environment }}:{{ $labels.pod }}'
            annotations:
              value: '{{ $labels.phase }}'
              summary: '{{ $labels.provider }}/{{ $labels.region }}: {{ $labels.cluster_name }}, Env: {{ $labels.environment }}, NS: {{ $labels.namespace }}'
              description: "Kubernetes pod: {{ $labels.pod }} of namespace: {{ $labels.namespace }} is in {{ $labels.phase }} state"
              troubleshooting: "Before call or @mention please check:\n*kubectl -n {{ $labels.namespace }} get po -o wide|grep -v Running*\nIf there are some pods that can't run inform appropriate person."
      - name: 'Kubernetes Deployment Status'
        rules:
          - alert: 'Deployment Replicas Unavailable'
            expr: >
              sum by (provider,cluster_name,region,environment,deployment,namespace)
                (avg_over_time(kube_deployment_status_replicas_unavailable[2m])) >= 1
            for: 2m
            labels:
              severity: critical
              owner: devops
              customer: '{{ $labels.provider }}:{{ $labels.region }}:{{ $labels.cluster_name }}:{{ $labels.environment }}:{{ $labels.deployment }}'
            annotations:
              value: '{{ $value | printf "%.0f" }}'
              summary: "{{ $labels.provider }}/{{ $labels.region }}: {{ $labels.cluster_name }}, Env: {{ $labels.environment }}, NS: {{ $labels.namespace }}"
              description: '{{ $value | printf "%.0f" }} replicas of deployment {{ $labels.deployment }} are unavailable'
              troubleshooting: 'Inform Higher Level OPS'

extraScrapeConfigs: |
   - job_name: 'dev kubernetes monitoring'
     scheme: http
     scrape_interval: 25s
     scrape_timeout: 25s
     metrics_path: /federate
     honor_labels: true
     params:
       match[]:
         - '{__name__=~".+"}'
     static_configs:
       - targets: ['monitoring-stack-server.prometheus.svc:80']
         labels:
           instance: localhost
           provider: k3s
           region: am
           cluster_name: local-cluster
           environment: dev
   - job_name: kubernetes-argocd
     scrape_interval: 10s
     scrape_timeout: 10s
     kubernetes_sd_configs:
       - role: pod
     relabel_configs:
       - source_labels: [__meta_kubernetes_namespace]
         action: replace
         target_label: namespace
       - source_labels: [__meta_kubernetes_pod_node_name]
         action: replace
         target_label: instance
       - source_labels: [__meta_kubernetes_pod_name]
         action: replace
         target_label: pod
       - source_labels: [__address__]
         action: replace
         regex: ([^:]+)(?::\d+)?
         replacement: ${1}:8082
         target_label: __address__
       - replacement: /metrics
         source_labels: [__metrics_path__]
         target_label: __metrics_path__
       - source_labels: [__meta_kubernetes_namespace]
         action: keep
         regex: argocd

   - job_name: kubernetes-argo-rollouts
     scrape_interval: 10s
     scrape_timeout: 10s
     kubernetes_sd_configs:
       - role: pod
     relabel_configs:
       - source_labels: [__meta_kubernetes_namespace]
         action: replace
         target_label: namespace
       - source_labels: [__meta_kubernetes_pod_node_name]
         action: replace
         target_label: instance
       - source_labels: [__meta_kubernetes_pod_name]
         action: replace
         target_label: pod
       - source_labels: [__address__]
         action: replace
         regex: ([^:]+)(?::\d+)?
         replacement: ${1}:8090
         target_label: __address__
       - replacement: /metrics
         source_labels: [__metrics_path__]
         target_label: __metrics_path__
       - source_labels: [__meta_kubernetes_namespace]
         action: keep
         regex: argo-rollouts

# deploys server, alertmanager, node-exporter, pushgateway
# on this namespace
forceNamespace: prometheus

# adds additional scrape configs to prometheus.yml
#extraScrapeConfigs: |

# ====================== Filebeat ============================

filebeat:
  # Deploy filebeat
  enabled: true
  daemonset:
  # Filebeat image to deploy
  image: docker.elastic.co/beats/filebeat:7.16.2
  affinity: {}
  resources:
    limits:
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
        - type: container
          paths:
            - /var/log/containers/monitoring-stack-prometheus*.log
          exclude_files: []
          fields: {log_type: k8s_logs}
          tail_files: true
          processors:
            - add_kubernetes_metadata:
                in_cluster: true
                host: ${NODE_NAME}
                matchers:
                - logs_path:
                    logs_path: "/var/log/containers/"
  # An output to send logs
  output: logstash
  loadbalance: true
  output_hosts:
    - logstash-host1:port
    - logstash-host2:port

# ====================== Promtail ============================

promtail:
  enabled: false
  namespace:
    name: promtail
  daemonset:
    image: grafana/promtail:2.3.0
    affinity: {}
    lokiEndpoint: http://loki-endpoint:port/loki/api/v1/push
    resources:
      requests:
        memory: 30Mi
        cpu: 0.01
      limits:
        memory: 150Mi
        cpu: 0.3
  promtailConfig:
    external_labels:
      provider: "AWS"
      region: "us-east1"
      cluster_name: "some-cluster-name"
      environment: "dev"
    scrape_configs:
      - job_name: kubernetes-full-logging
        pipeline_stages:
          - docker: {}
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: keep
            regex: SOME_CONTAINER_NAME
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container_name
          - source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node_name
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod_name
          - replacement: /var/log/containers/$1*log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: __path__
